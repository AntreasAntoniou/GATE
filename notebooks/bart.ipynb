{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/main/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForQuestionAnswering\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context tokens: tensor([   0,  133,  812,    9, 1470,   16, 2201,    4,    2]), \n",
      "Question tokens: tensor([   0, 2264,   16,    5,  812,    9, 1470,  116,    2]), \n",
      "Answer tokens: tensor([    0, 32826,     2]), \n",
      " Padding token id: 1, \n",
      " BOS token id: 0, \n",
      " EOS token id: 2, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the BART tokenizer and model\n",
    "tokenizer = BartTokenizer.from_pretrained( \"valhalla/bart-large-finetuned-squadv1\")\n",
    "model = BartForQuestionAnswering.from_pretrained( \"valhalla/bart-large-finetuned-squadv1\")\n",
    "# Define the context, question, and answer\n",
    "context = \"The capital of France is Paris.\"\n",
    "question = \"What is the capital of France?\"\n",
    "answer = \"Paris\"\n",
    "\n",
    "context_tokens = tokenizer(context, return_tensors='pt')['input_ids'].view(-1)\n",
    "question_tokens = tokenizer(question, return_tensors='pt')['input_ids'].view(-1)\n",
    "answer_tokens = tokenizer(answer, return_tensors='pt')['input_ids'].view(-1)\n",
    "\n",
    "print(f\"Context tokens: {context_tokens}, \\n\"\n",
    "      f\"Question tokens: {question_tokens}, \\n\"\n",
    "      f\"Answer tokens: {answer_tokens}, \\n\",\n",
    "      f\"Padding token id: {tokenizer.pad_token_id}, \\n\",\n",
    "      f\"BOS token id: {tokenizer.bos_token_id}, \\n\",\n",
    "      f\"EOS token id: {tokenizer.eos_token_id}, \\n\",)\n",
    "\n",
    "combined_tokens = torch.cat([context_tokens[:-1], question_tokens[1:-1], answer_tokens[1:]], dim=0)\n",
    "context_question_tokens = torch.cat([context_tokens[:-1], question_tokens[1:]], dim=0).unsqueeze(0)\n",
    "answer_start_idx = len(context_tokens) - 1 + len(question_tokens) - 2\n",
    "answer_end_idx = answer_start_idx + len(answer_tokens) - 2\n",
    "\n",
    "combined_tokens = combined_tokens.unsqueeze(0)\n",
    "answer_start_idx = torch.tensor([answer_start_idx]).unsqueeze(0)\n",
    "answer_end_idx = torch.tensor([answer_end_idx]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">encoder_outputs\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'last_hidden_state'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0150</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0184</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0024</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0036</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0229</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0058</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2851</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0260</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3642</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2097</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0389</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0300</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1509</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0110</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1628</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1412</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0178</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0624</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1158</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1886</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1772</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0938</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0355</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0410</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1504</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2321</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0447</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1199</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1284</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0939</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0927</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1256</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0512</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0361</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1075</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1066</span><span style=\"font-weight: bold\">]]]</span>,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">NativeLayerNormBackward0</span><span style=\"font-weight: bold\">&gt;)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_states'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'attentions'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "encoder_outputs\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'last_hidden_state'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0.0150\u001b[0m,  \u001b[1;36m0.0184\u001b[0m, \u001b[1;36m-0.0024\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.0036\u001b[0m, \u001b[1;36m-0.0229\u001b[0m, \u001b[1;36m-0.0058\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.2851\u001b[0m,  \u001b[1;36m0.0260\u001b[0m, \u001b[1;36m-0.3642\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.2097\u001b[0m, \u001b[1;36m-0.0389\u001b[0m, \u001b[1;36m-0.0300\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.1509\u001b[0m,  \u001b[1;36m0.0110\u001b[0m,  \u001b[1;36m0.1628\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.1412\u001b[0m,  \u001b[1;36m0.0178\u001b[0m, \u001b[1;36m-0.0624\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[33m...\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.1158\u001b[0m, \u001b[1;36m-0.1886\u001b[0m,  \u001b[1;36m0.1772\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.0938\u001b[0m,  \u001b[1;36m0.0355\u001b[0m, \u001b[1;36m-0.0410\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.1504\u001b[0m, \u001b[1;36m-0.2321\u001b[0m,  \u001b[1;36m0.0447\u001b[0m,  \u001b[33m...\u001b[0m,  \u001b[1;36m0.1199\u001b[0m,  \u001b[1;36m0.1284\u001b[0m,  \u001b[1;36m0.0939\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.0927\u001b[0m,  \u001b[1;36m0.1256\u001b[0m, \u001b[1;36m-0.0512\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.0361\u001b[0m, \u001b[1;36m-0.1075\u001b[0m,  \u001b[1;36m0.1066\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mNativeLayerNormBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'hidden_states'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'attentions'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">last_hidden_state: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "last_hidden_state: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m17\u001b[0m, \u001b[1;36m1024\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">hidden_states: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "hidden_states: \u001b[3;35mNone\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">attentions: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "attentions: \u001b[3;35mNone\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">encoder_outputs\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'last_hidden_state'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0113</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0185</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0048</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0053</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0167</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0071</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2570</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0737</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3358</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1560</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0068</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0128</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1610</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0081</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1093</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0902</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0416</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0264</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1389</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0329</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1662</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1552</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0731</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2212</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1460</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2380</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1070</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0674</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0898</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1011</span><span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0747</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0827</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0550</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0324</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1199</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1103</span><span style=\"font-weight: bold\">]]])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_states'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'attentions'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "encoder_outputs\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'last_hidden_state'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0.0113\u001b[0m,  \u001b[1;36m0.0185\u001b[0m,  \u001b[1;36m0.0048\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.0053\u001b[0m, \u001b[1;36m-0.0167\u001b[0m, \u001b[1;36m-0.0071\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.2570\u001b[0m, \u001b[1;36m-0.0737\u001b[0m, \u001b[1;36m-0.3358\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.1560\u001b[0m,  \u001b[1;36m0.0068\u001b[0m, \u001b[1;36m-0.0128\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.1610\u001b[0m,  \u001b[1;36m0.0081\u001b[0m,  \u001b[1;36m0.1093\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.0902\u001b[0m,  \u001b[1;36m0.0416\u001b[0m, \u001b[1;36m-0.0264\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[33m...\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.1389\u001b[0m,  \u001b[1;36m0.0329\u001b[0m, \u001b[1;36m-0.1662\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.1552\u001b[0m, \u001b[1;36m-0.0731\u001b[0m,  \u001b[1;36m0.2212\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-0.1460\u001b[0m, \u001b[1;36m-0.2380\u001b[0m,  \u001b[1;36m0.1070\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.0674\u001b[0m, \u001b[1;36m-0.0898\u001b[0m, \u001b[1;36m-0.1011\u001b[0m\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0.0747\u001b[0m,  \u001b[1;36m0.0827\u001b[0m, \u001b[1;36m-0.0550\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-0.0324\u001b[0m, \u001b[1;36m-0.1199\u001b[0m,  \u001b[1;36m0.1103\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'hidden_states'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'attentions'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">last_hidden_state: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "last_hidden_state: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m1024\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">hidden_states: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "hidden_states: \u001b[3;35mNone\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">attentions: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "attentions: \u001b[3;35mNone\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Perform a forward pass and compute the loss\n",
    "model.train()\n",
    "outputs = model(input_ids=combined_tokens, start_positions=answer_start_idx, end_positions=answer_end_idx)\n",
    "loss = outputs.loss\n",
    "\n",
    "# Backpropagate the loss and perform an optimization step\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Perform inference on the same data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=context_question_tokens)\n",
    "\n",
    "for key, value in outputs.__dict__.items():\n",
    "    output_string = f\"{key}: {value}\" if not isinstance(value, torch.Tensor) else f\"{key}: {value.shape}\"\n",
    "    # print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/main/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  3%|▎         | 3/100 [00:00<00:04, 20.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5292856693267822\n",
      "2.5621626377105713\n",
      "2.5013720989227295\n",
      "2.8336524963378906\n",
      "2.499972343444824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:00<00:04, 19.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.569439172744751\n",
      "2.568347454071045\n",
      "2.5246505737304688\n",
      "2.4872758388519287\n",
      "2.0676064491271973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:00<00:04, 19.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5730204582214355\n",
      "2.6153359413146973\n",
      "2.6455748081207275\n",
      "2.724306344985962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:00<00:04, 19.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.322098970413208\n",
      "3.0020980834960938\n",
      "2.742515802383423\n",
      "2.289710521697998\n",
      "2.3434908390045166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:01<00:03, 19.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7114408016204834\n",
      "2.3565027713775635\n",
      "2.7029733657836914\n",
      "2.065701723098755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:01<00:03, 19.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5974442958831787\n",
      "2.4911653995513916\n",
      "2.45788311958313\n",
      "2.506070852279663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [00:01<00:03, 19.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3668932914733887\n",
      "2.6329641342163086\n",
      "2.79579496383667\n",
      "2.931165933609009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [00:01<00:03, 17.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.47560715675354\n",
      "2.96134352684021\n",
      "2.9773855209350586\n",
      "2.551283121109009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [00:01<00:03, 18.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.604534387588501\n",
      "2.386500120162964\n",
      "2.4230661392211914\n",
      "2.4694020748138428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [00:02<00:03, 16.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2694835662841797\n",
      "2.8106610774993896\n",
      "2.2715163230895996\n",
      "2.8672382831573486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [00:02<00:03, 15.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6258745193481445\n",
      "2.5032567977905273\n",
      "2.563673973083496\n",
      "2.29408597946167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:02<00:03, 15.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.661142110824585\n",
      "2.4053564071655273\n",
      "2.5236589908599854\n",
      "2.9230830669403076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [00:03<00:02, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.811673164367676\n",
      "2.58351731300354\n",
      "2.7362098693847656\n",
      "2.2809839248657227\n",
      "2.7075917720794678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [00:03<00:02, 18.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5175986289978027\n",
      "2.688176155090332\n",
      "2.836557626724243\n",
      "2.2819600105285645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [00:03<00:02, 17.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1921603679656982\n",
      "3.1061019897460938\n",
      "2.3989274501800537\n",
      "4.018486022949219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [00:03<00:02, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7878267765045166\n",
      "2.612661600112915\n",
      "2.637922525405884\n",
      "2.784435510635376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [00:03<00:01, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3776395320892334\n",
      "2.651190757751465\n",
      "2.6549582481384277\n",
      "2.4860148429870605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [00:04<00:01, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.716874122619629\n",
      "2.9579555988311768\n",
      "2.3414266109466553\n",
      "2.7561819553375244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [00:04<00:01, 17.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.276392698287964\n",
      "2.6744790077209473\n",
      "2.6531546115875244\n",
      "2.9054059982299805\n",
      "2.564725399017334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [00:04<00:00, 18.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2358267307281494\n",
      "2.898979425430298\n",
      "2.725952386856079\n",
      "2.4379076957702637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [00:04<00:00, 18.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.532442331314087\n",
      "2.1732614040374756\n",
      "2.5355582237243652\n",
      "2.7551121711730957\n",
      "2.9170961380004883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [00:05<00:00, 19.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.461033582687378\n",
      "2.6076159477233887\n",
      "2.9964075088500977\n",
      "2.7833333015441895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [00:05<00:00, 19.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.504783868789673\n",
      "2.8673207759857178\n",
      "2.2754602432250977\n",
      "3.0448973178863525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 18.02it/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2931196689605713\n",
      "2.8419203758239746\n",
      "Generated answer: \n",
      "\n",
      "The capital is Paris. It is located in the heart of the French capital. The capital was founded in 1789, and it is still there today. In 1791, the city was divided into two\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Set up the question-answer pair as a single string\n",
    "question = \"What is the capital of France?\"\n",
    "answer = \"The capital of France is Paris.\"\n",
    "text = question + \" \" + answer\n",
    "\n",
    "# Encode the text, and return tensors\n",
    "inputs = tokenizer.encode_plus(text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "# Extract the input_ids and attention_mask\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "# Set up the optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=1)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "for i in tqdm(range(100)):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "\n",
    "    # Get the loss\n",
    "    loss = outputs.loss\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "    print(loss.item())\n",
    "\n",
    "# Do a prediction (inference)\n",
    "model.eval()\n",
    "\n",
    "# Let's ask the model the same question\n",
    "input_ids = tokenizer.encode(question, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate a response\n",
    "generated = model.generate(input_ids, max_length=50, num_beams=5, temperature=1.5, no_repeat_ngram_size=2)\n",
    "generated_answer = tokenizer.decode(generated[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Generated answer: {generated_answer}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
