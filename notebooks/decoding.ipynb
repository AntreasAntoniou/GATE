{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['transformer.h.5.crossattention.c_attn.weight', 'transformer.h.2.crossattention.q_attn.weight', 'transformer.h.4.ln_cross_attn.weight', 'transformer.h.5.crossattention.bias', 'transformer.h.3.ln_cross_attn.weight', 'transformer.h.0.crossattention.c_proj.weight', 'transformer.h.5.ln_cross_attn.weight', 'transformer.h.3.crossattention.c_proj.weight', 'transformer.h.3.crossattention.q_attn.weight', 'transformer.h.4.crossattention.c_proj.weight', 'transformer.h.2.crossattention.masked_bias', 'transformer.h.1.crossattention.c_proj.bias', 'transformer.h.0.crossattention.c_proj.bias', 'transformer.h.4.crossattention.c_proj.bias', 'transformer.h.0.crossattention.masked_bias', 'transformer.h.3.crossattention.c_attn.weight', 'transformer.h.1.crossattention.c_attn.weight', 'transformer.h.3.crossattention.bias', 'transformer.h.0.ln_cross_attn.weight', 'transformer.h.1.ln_cross_attn.weight', 'transformer.h.0.crossattention.bias', 'transformer.h.5.crossattention.c_proj.bias', 'transformer.h.0.crossattention.c_attn.weight', 'transformer.h.2.crossattention.c_proj.bias', 'transformer.h.3.crossattention.c_proj.bias', 'transformer.h.2.ln_cross_attn.weight', 'transformer.h.3.crossattention.masked_bias', 'transformer.h.4.crossattention.bias', 'transformer.h.4.crossattention.c_attn.weight', 'transformer.h.1.crossattention.masked_bias', 'transformer.h.0.crossattention.q_attn.weight', 'transformer.h.4.crossattention.masked_bias', 'transformer.h.1.crossattention.bias', 'transformer.h.1.crossattention.c_proj.weight', 'transformer.h.1.crossattention.q_attn.weight', 'transformer.h.5.crossattention.masked_bias', 'transformer.h.2.crossattention.bias', 'transformer.h.5.crossattention.c_proj.weight', 'transformer.h.2.crossattention.c_proj.weight', 'transformer.h.2.crossattention.c_attn.weight', 'transformer.h.4.crossattention.q_attn.weight', 'transformer.h.5.crossattention.q_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">GPT2Config <span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"_name_or_path\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"distilgpt2\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"_num_labels\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"activation_function\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"gelu_new\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"add_cross_attention\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"architectures\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"GPT2LMHeadModel\"</span>\n",
       "  <span style=\"font-weight: bold\">]</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"attn_pdrop\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"bos_token_id\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50256</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"embd_pdrop\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"eos_token_id\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50256</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"id2label\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"0\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"LABEL_0\"</span>\n",
       "  <span style=\"font-weight: bold\">}</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"initializer_range\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"label2id\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"LABEL_0\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "  <span style=\"font-weight: bold\">}</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"layer_norm_epsilon\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"model_type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"gpt2\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_ctx\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_embd\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_head\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_inner\"</span>: null,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_layer\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"n_positions\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"reorder_and_upcast_attn\"</span>: false,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"resid_pdrop\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"scale_attn_by_inverse_layer_idx\"</span>: false,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"scale_attn_weights\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_activation\"</span>: null,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_first_dropout\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_proj_to_labels\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"cls_index\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"summary_use_proj\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"task_specific_params\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"text-generation\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"do_sample\"</span>: true,\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"max_length\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "  <span style=\"font-weight: bold\">}</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"transformers_version\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"4.28.1\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"use_cache\"</span>: true,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"vocab_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50257</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "GPT2Config \u001b[1m{\u001b[0m\n",
       "  \u001b[32m\"_name_or_path\"\u001b[0m: \u001b[32m\"distilgpt2\"\u001b[0m,\n",
       "  \u001b[32m\"_num_labels\"\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "  \u001b[32m\"activation_function\"\u001b[0m: \u001b[32m\"gelu_new\"\u001b[0m,\n",
       "  \u001b[32m\"add_cross_attention\"\u001b[0m: true,\n",
       "  \u001b[32m\"architectures\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "    \u001b[32m\"GPT2LMHeadModel\"\u001b[0m\n",
       "  \u001b[1m]\u001b[0m,\n",
       "  \u001b[32m\"attn_pdrop\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"bos_token_id\"\u001b[0m: \u001b[1;36m50256\u001b[0m,\n",
       "  \u001b[32m\"embd_pdrop\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"eos_token_id\"\u001b[0m: \u001b[1;36m50256\u001b[0m,\n",
       "  \u001b[32m\"id2label\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"0\"\u001b[0m: \u001b[32m\"LABEL_0\"\u001b[0m\n",
       "  \u001b[1m}\u001b[0m,\n",
       "  \u001b[32m\"initializer_range\"\u001b[0m: \u001b[1;36m0.02\u001b[0m,\n",
       "  \u001b[32m\"label2id\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"LABEL_0\"\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "  \u001b[1m}\u001b[0m,\n",
       "  \u001b[32m\"layer_norm_epsilon\"\u001b[0m: \u001b[1;36m1e-05\u001b[0m,\n",
       "  \u001b[32m\"model_type\"\u001b[0m: \u001b[32m\"gpt2\"\u001b[0m,\n",
       "  \u001b[32m\"n_ctx\"\u001b[0m: \u001b[1;36m1024\u001b[0m,\n",
       "  \u001b[32m\"n_embd\"\u001b[0m: \u001b[1;36m768\u001b[0m,\n",
       "  \u001b[32m\"n_head\"\u001b[0m: \u001b[1;36m12\u001b[0m,\n",
       "  \u001b[32m\"n_inner\"\u001b[0m: null,\n",
       "  \u001b[32m\"n_layer\"\u001b[0m: \u001b[1;36m6\u001b[0m,\n",
       "  \u001b[32m\"n_positions\"\u001b[0m: \u001b[1;36m1024\u001b[0m,\n",
       "  \u001b[32m\"reorder_and_upcast_attn\"\u001b[0m: false,\n",
       "  \u001b[32m\"resid_pdrop\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"scale_attn_by_inverse_layer_idx\"\u001b[0m: false,\n",
       "  \u001b[32m\"scale_attn_weights\"\u001b[0m: true,\n",
       "  \u001b[32m\"summary_activation\"\u001b[0m: null,\n",
       "  \u001b[32m\"summary_first_dropout\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "  \u001b[32m\"summary_proj_to_labels\"\u001b[0m: true,\n",
       "  \u001b[32m\"summary_type\"\u001b[0m: \u001b[32m\"cls_index\"\u001b[0m,\n",
       "  \u001b[32m\"summary_use_proj\"\u001b[0m: true,\n",
       "  \u001b[32m\"task_specific_params\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"text-generation\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "      \u001b[32m\"do_sample\"\u001b[0m: true,\n",
       "      \u001b[32m\"max_length\"\u001b[0m: \u001b[1;36m50\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "  \u001b[1m}\u001b[0m,\n",
       "  \u001b[32m\"transformers_version\"\u001b[0m: \u001b[32m\"4.28.1\"\u001b[0m,\n",
       "  \u001b[32m\"use_cache\"\u001b[0m: true,\n",
       "  \u001b[32m\"vocab_size\"\u001b[0m: \u001b[1;36m50257\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\", add_cross_attention = True)\n",
    "print(model.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.5252</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">NllLossBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50257</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m9.5252\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mNllLossBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m50257\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assume we have the following input sequence\n",
    "sample_sequence = [\"I love deep learning and transformers.\", \"Wow, look at that beautiful sunset.\", \"I wonder what is going to happen next.\"]\n",
    "\n",
    "def generate_qa_tokens(input_sequence_list):\n",
    "    question_tokens = []\n",
    "    answer_tokens = []\n",
    "    for input_sequence in input_sequence_list:\n",
    "        question_token = input_sequence[:len(input_sequence) // 2]\n",
    "        answer_token = input_sequence[len(input_sequence) // 2:]\n",
    "        question_tokens.append(question_token)\n",
    "        answer_tokens.append(answer_token)\n",
    "    \n",
    "    question_tokens = tokenizer(question_tokens, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    answer_tokens = tokenizer(answer_tokens, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return question_tokens, answer_tokens\n",
    "        \n",
    "question_encoder_tokens, answer_encoder_tokens = generate_qa_tokens(sample_sequence)       \n",
    "outputs = model(**question_encoder_tokens, encoder_hidden_states=torch.randn(3, 10, 768), labels=answer_encoder_tokens[\"input_ids\"])\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits\n",
    "\n",
    "print(loss, logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "class SimpleVQATransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_encoder: nn.Module,\n",
    "        image_encoder_transforms: nn.Module,\n",
    "        image_encoder_num_features: int,\n",
    "        text_encoder: nn.Module,\n",
    "        text_encoder_num_features: int,\n",
    "        text_encoder_transforms: nn.Module,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_encoder = image_encoder\n",
    "        self.text_encoder = text_encoder\n",
    "\n",
    "        self.image_encoder_num_features = image_encoder_num_features\n",
    "        self.text_encoder_num_features = text_encoder_num_features\n",
    "        \n",
    "        self.image_encoder_transforms = image_encoder_transforms\n",
    "        self.text_encoder_transforms = text_encoder_transforms\n",
    "\n",
    "        self.text_decoder_tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"distilgpt2\"\n",
    "        )\n",
    "        self.text_decoder_tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "        \n",
    "        self.text_decoder = AutoModelForCausalLM.from_pretrained(\"distilgpt2\",  add_cross_attention=True)\n",
    "        \n",
    "        self.combine_embeddings_linear = nn.Linear(\n",
    "            image_encoder_num_features + text_encoder_num_features,\n",
    "            self.text_decoder.config.vocab_size,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_dict: Optional[Dict] = None,\n",
    "        image_encoder_tokens: Optional[torch.Tensor] = None,\n",
    "        question_encoder_tokens: Optional[torch.Tensor] = None,\n",
    "        question_decoder_tokens: Optional[torch.Tensor] = None,\n",
    "        answer_decoder_tokens: Optional[torch.Tensor] = None,\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        if input_dict is not None:\n",
    "            image_encoder_tokens = input_dict[\"image_tokens\"]\n",
    "            question_encoder_tokens = input_dict[\"question_tokens\"]\n",
    "\n",
    "        image_embeddings = self.image_encoder(image_encoder_tokens)[\"image_features\"]\n",
    "\n",
    "        question_text_embeddings = self.text_encoder(question_encoder_tokens)[\n",
    "            \"text_features\"\n",
    "        ]\n",
    "\n",
    "        concat_embeddings = torch.cat(\n",
    "            [image_embeddings, question_text_embeddings], dim=1\n",
    "        )\n",
    "\n",
    "        combine_embeddings = self.combine_embeddings_linear(concat_embeddings)\n",
    "        combine_embeddings = combine_embeddings.unsqueeze(1)\n",
    "\n",
    "        if answer_encoder_tokens is not None:\n",
    "            return self.text_decoder(**question_decoder_tokens, encoder_hidden_states=combine_embeddings, labels=answer_decoder_tokens[\"input_ids\"])\n",
    "        else:\n",
    "            return self.text_decoder(**question_decoder_tokens, encoder_hidden_states=combine_embeddings)\n",
    "\n",
    "    def get_transforms(self):\n",
    "        return {\"text_decoder\": lambda x: self.text_decoder_tokenizer(x), \n",
    "                \"image_encoder\": self.image_encoder_transforms, \n",
    "                \"text_encoder\": self.text_encoder_transforms}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['transformer.h.5.crossattention.c_attn.weight', 'transformer.h.2.crossattention.q_attn.weight', 'transformer.h.4.ln_cross_attn.weight', 'transformer.h.5.crossattention.bias', 'transformer.h.3.ln_cross_attn.weight', 'transformer.h.0.crossattention.c_proj.weight', 'transformer.h.5.ln_cross_attn.weight', 'transformer.h.3.crossattention.c_proj.weight', 'transformer.h.3.crossattention.q_attn.weight', 'transformer.h.4.crossattention.c_proj.weight', 'transformer.h.2.crossattention.masked_bias', 'transformer.h.1.crossattention.c_proj.bias', 'transformer.h.0.crossattention.c_proj.bias', 'transformer.h.4.crossattention.c_proj.bias', 'transformer.h.0.crossattention.masked_bias', 'transformer.h.3.crossattention.c_attn.weight', 'transformer.h.1.crossattention.c_attn.weight', 'transformer.h.3.crossattention.bias', 'transformer.h.0.ln_cross_attn.weight', 'transformer.h.1.ln_cross_attn.weight', 'transformer.h.0.crossattention.bias', 'transformer.h.5.crossattention.c_proj.bias', 'transformer.h.0.crossattention.c_attn.weight', 'transformer.h.2.crossattention.c_proj.bias', 'transformer.h.3.crossattention.c_proj.bias', 'transformer.h.2.ln_cross_attn.weight', 'transformer.h.3.crossattention.masked_bias', 'transformer.h.4.crossattention.bias', 'transformer.h.4.crossattention.c_attn.weight', 'transformer.h.1.crossattention.masked_bias', 'transformer.h.0.crossattention.q_attn.weight', 'transformer.h.4.crossattention.masked_bias', 'transformer.h.1.crossattention.bias', 'transformer.h.1.crossattention.c_proj.weight', 'transformer.h.1.crossattention.q_attn.weight', 'transformer.h.5.crossattention.masked_bias', 'transformer.h.2.crossattention.bias', 'transformer.h.5.crossattention.c_proj.weight', 'transformer.h.2.crossattention.c_proj.weight', 'transformer.h.2.crossattention.c_attn.weight', 'transformer.h.4.crossattention.q_attn.weight', 'transformer.h.5.crossattention.q_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from gate.models.backbones.clip import CLIPAdapter\n",
    "\n",
    "\n",
    "backbone_model = CLIPAdapter(model_name=\"openai/clip-vit-base-patch16\", pretrained=True)\n",
    "clip_transforms = backbone_model.get_transforms()\n",
    "vqa_model = SimpleVQATransformer(image_encoder=backbone_model.vision_model, \n",
    "                                 image_encoder_transforms=clip_transforms[\"image\"], \n",
    "                                 image_encoder_num_features=512, \n",
    "                                 text_encoder=backbone_model.text_model, \n",
    "                                 text_encoder_transforms=clip_transforms[\"text\"], \n",
    "                                 text_encoder_num_features=512)\n",
    "vqa_transforms = vqa_model.get_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "from urllib.request import urlopen\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "from transformers.models.clip.modeling_clip import CLIPOutput\n",
    "import timm\n",
    "import PIL.Image as Image\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "vqa_model.to(\"cuda\")\n",
    "img = Image.open(\n",
    "            urlopen(\n",
    "                \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png\"\n",
    "            )\n",
    "        )\n",
    "images = [img, img, img]\n",
    "questions = [\"What is in the image?\", \"Who is in the image?\", \"What is the weather like?\"]\n",
    "answers = [\"beignets\", \"a cat\", \"sunny\"]\n",
    "\n",
    "encoder_images = [vqa_transforms[\"image_encoder\"](image) for image in images]\n",
    "encoder_questions = [vqa_transforms[\"text_encoder\"](question) for question in questions.copy()]\n",
    "decoder_questions = [vqa_transforms[\"text_decoder\"](question) for question in questions.copy()]\n",
    "decoder_answers = [vqa_transforms[\"text_decoder\"](answer) for answer in answers]\n",
    "\n",
    "encoder_images = torch.stack(encoder_images).to(\"cuda\")\n",
    "encoder_questions = torch.stack(encoder_questions).to(\"cuda\")\n",
    "# decoder_questions = torch.stack(decoder_questions).to(\"cuda\")\n",
    "# decoder_answers = torch.stack(decoder_answers).to(\"cuda\")\n",
    "\n",
    "output = vqa_model(image_encoder_tokens=encoder_images, question_encoder_tokens=encoder_questions, question_decoder_tokens=decoder_questions, answer_decoder_tokens=decoder_answers)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimal-ml-template",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
